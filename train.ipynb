{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torcheeg torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    accelerator = \"gpu\"\n",
    "    pin_memory = True\n",
    "    print(\"GPU is available. Training will use GPU acceleration.\")\n",
    "else:\n",
    "    accelerator = \"cpu\"\n",
    "    pin_memory = False\n",
    "    print(\"WARNING: GPU not available, using CPU instead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheeg.datasets import DREAMERDataset\n",
    "from torcheeg import transforms\n",
    "from torcheeg.datasets.constants import DREAMER_CHANNEL_LOCATION_DICT\n",
    "from torcheeg.model_selection import KFoldGroupbyTrial\n",
    "from torcheeg.models import CCNN\n",
    "from torcheeg.trainers import ClassifierTrainer\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "BASE_PATH = '/content/drive/MyDrive/datasets/DREAMER'\n",
    "# BASE_PATH = './data'\n",
    "\n",
    "IO_PATH = os.path.join(BASE_PATH, '/transformed/')\n",
    "MAT_FILE_PATH = os.path.join(BASE_PATH, '/DREAMER.mat')\n",
    "MODEL_SAVE_PATH = os.path.join(BASE_PATH, '/model/')\n",
    "\n",
    "if not (os.path.exists(IO_PATH) and os.path.exists(MAT_FILE_PATH) and os.path.exists(MODEL_SAVE_PATH)):\n",
    "    raise(\"Make sure the base path is correct and accessible - it should have 'transformed' folder, 'model' folder, and 'DREAMER.mat' file\")\n",
    "\n",
    "\n",
    "SEED:int = 42\n",
    "BATCH_SIZE:int = 64\n",
    "N_WORKERS:int = 4   # rule of thumb: n_workers = 4 * n_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://zenodo.org/records/546113\n",
    "# Katsigiannis, S., & Ramzan, N. (2017). DREAMER: A Database for Emotion Recognition through EEG and ECG Signals from Wireless Low-cost Off-the-Shelf Devices [Data set]. Zenodo. https://doi.org/10.1109/JBHI.2017.2688239\n",
    "# we predict arousal (intensity of emotion) and valence (negativity of emotion) on scale of 1-5, negative and aroused means fear (or masochism (me fr))\n",
    "dataset = DREAMERDataset(\n",
    "    io_path=IO_PATH,\n",
    "    mat_path=MAT_FILE_PATH,\n",
    "    \n",
    "    offline_transform=transforms.Compose([\n",
    "        transforms.BandDifferentialEntropy(apply_to_baseline=True),\n",
    "        transforms.ToGrid(DREAMER_CHANNEL_LOCATION_DICT, apply_to_baseline=True)\n",
    "    ]),\n",
    "    \n",
    "    online_transform=transforms.Compose([\n",
    "        transforms.BaselineRemoval(),\n",
    "         transforms.ToTensor()\n",
    "    ]),\n",
    "    \n",
    "    label_transform=transforms.Compose([\n",
    "        transforms.Select(['valence', 'arousal']),\n",
    "        lambda x: torch.tensor(1 if x[0] < 3 and x[1] > 3 else 0, dtype=torch.long)\n",
    "    ]),\n",
    "    \n",
    "    num_worker=N_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation is used during training for evaluating each batch\n",
    "# test is saved to after (even if we don't train on val anyway, mechanisms like picking the best may still have 'val bias')\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.15 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, \n",
    "    [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "print(f\"Dataset split: {train_size} training, {val_size} validation, {test_size} test samples\")\n",
    "\n",
    "\n",
    "\n",
    "# when training a GPU, we put the memory on a special 'pinned' region for faster transfer between CPU and GPU\n",
    "# we shuffle the data in training to avoid it learning some patterns there (across batches) - no need on eval, since metrics will be the same\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True,\n",
    "    num_workers=N_WORKERS,\n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False,\n",
    "    num_workers=N_WORKERS,\n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=N_WORKERS,\n",
    "    pin_memory=pin_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CCNN(\n",
    "    num_classes=2,  # Binary classification (fear vs. non-fear)\n",
    "    in_channels=4,  # 4 frequency bands\n",
    "    grid_size=(7, 7)    # 14 channels mapped to 7 by 7 grid (not every one has an electrode)\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    # saves the currently model to specific file\n",
    "    ModelCheckpoint(\n",
    "        dirpath=MODEL_SAVE_PATH,\n",
    "        filename='best-model-{epoch:02d}-{val_accuracy:.4f}',\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_top_k=1\n",
    "    ),\n",
    "    \n",
    "    # saves the last model to specific file\n",
    "    ModelCheckpoint(\n",
    "        dirpath=MODEL_SAVE_PATH,\n",
    "        filename='last-model',\n",
    "        save_last=True\n",
    "    ),\n",
    "   \n",
    "    # tries to detect overfitting by stopping if the val_accuracy stops improving for 10 epochs\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        mode='max',\n",
    "        verbose=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "trainer = ClassifierTrainer(\n",
    "    model=model,\n",
    "    num_classes=2,\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    accelerator=accelerator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nStarting model training...\")\n",
    "trainer.fit(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    max_epochs=100,\n",
    "    default_root_dir=MODEL_SAVE_PATH,\n",
    "    callbacks=callbacks,\n",
    "    enable_progress_bar=True,\n",
    "    enable_model_summary=True\n",
    ")\n",
    "# ends once the trainer is done (so most likely through EarlyStop, otherwise max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEvaluating model on test set...\")\n",
    "test_results = trainer.test(test_loader)[0]\n",
    "print(f\"Test accuracy: {test_results['test_accuracy']:.4f}\")\n",
    "print(f\"Test precision: {test_results['test_precision']:.4f}\")\n",
    "print(f\"Test recall: {test_results['test_recall']:.4f}\")\n",
    "print(f\"Test F1 score: {test_results['test_f1']:.4f}\")\n",
    "\n",
    "\n",
    "# the trainer saves the model checkpoints periodically and keeps data about eachs ones performance\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "if not best_model_path:\n",
    "    best_model_path = os.path.join(MODEL_SAVE_PATH + '/last-model.ckpt')\n",
    "\n",
    "\n",
    "# Save the best model in .pth format\n",
    "model = CCNN.load_from_checkpoint(best_model_path, num_classes=2, in_channels=4, grid_size=(7, 7))\n",
    "torch.save(model.state_dict(), os.path.join(MODEL_SAVE_PATH, 'fear_prediction_model.pth'))\n",
    "\n",
    "# Print a summary of the training process\n",
    "print(\"\\nTraining Summary:\")\n",
    "print(f\"Best validation accuracy: {trainer.checkpoint_callback.best_model_score:.4f}\")\n",
    "print(f\"Best model saved at: {best_model_path}\")\n",
    "print(f\"Final model saved as: {os.path.join(MODEL_SAVE_PATH, 'fear_prediction_model.pth')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
